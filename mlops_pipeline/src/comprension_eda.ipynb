{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "57e36fca",
            "metadata": {},
            "source": [
                "# Comprensi√≥n y An√°lisis Exploratorio de Datos (EDA)\n",
                "\n",
                "**Proyecto:** Pipeline MLOps - Predicci√≥n de Pago a Tiempo de Cr√©ditos\n",
                "\n",
                "**Autor:** Data Science Team\n",
                "\n",
                "---\n",
                "\n",
                "## Objetivo\n",
                "\n",
                "Realizar un an√°lisis exploratorio exhaustivo de los datos para:\n",
                "1. Comprender la estructura y caracter√≠sticas de los datos\n",
                "2. Identificar patrones, tendencias y anomal√≠as\n",
                "3. Detectar problemas de calidad de datos\n",
                "4. Establecer reglas de validaci√≥n\n",
                "5. Identificar transformaciones necesarias para el modelado\n",
                "\n",
                "## Contenido\n",
                "\n",
                "1. Carga de Datos y Configuraci√≥n\n",
                "2. Exploraci√≥n Inicial de Datos\n",
                "3. An√°lisis Univariable\n",
                "4. An√°lisis Bivariable\n",
                "5. An√°lisis Multivariable\n",
                "6. Reglas de Validaci√≥n\n",
                "7. Transformaciones Identificadas\n",
                "8. Conclusiones y Recomendaciones"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "17b24c12",
            "metadata": {},
            "source": [
                "## 1. Carga de Datos y Configuraci√≥n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1eca3b87",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importar librer√≠as necesarias\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "import warnings\n",
                "from scipy import stats\n",
                "from scipy.stats import chi2_contingency, pearsonr, spearmanr\n",
                "\n",
                "# Configuraci√≥n\n",
                "warnings.filterwarnings('ignore')\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette('husl')\n",
                "%matplotlib inline\n",
                "\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.max_rows', 100)\n",
                "pd.set_option('display.width', None)\n",
                "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
                "\n",
                "np.random.seed(42)\n",
                "\n",
                "print(\"‚úì Librer√≠as cargadas y configuradas\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3d40f6a8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cargar datos\n",
                "# Intentamos cargar desde la ruta relativa esperada\n",
                "try:\n",
                "    df = pd.read_excel('../../Base_de_datos.xlsx')\n",
                "    print(\"‚úì Datos cargados desde ruta relativa principal\")\n",
                "except FileNotFoundError:\n",
                "    try:\n",
                "        df = pd.read_excel('Base_de_datos.xlsx')\n",
                "        print(\"‚úì Datos cargados desde directorio actual\")\n",
                "    except FileNotFoundError:\n",
                "        # Ajuste para rutas absolutas si es necesario\n",
                "        print(\"‚ùå No se encontr√≥ el archivo Base_de_datos.xlsx en las rutas esperadas\")\n",
                "\n",
                "# Verificar carga\n",
                "if 'df' in locals():\n",
                "    print(f\"‚úì Datos cargados: {df.shape[0]:,} filas x {df.shape[1]} columnas\")\n",
                "    # Crear una copia para trabajar sin modificar el original\n",
                "    df_original = df.copy()\n",
                "    print(\"‚úì Copia de seguridad creada\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Error cr√≠tico: No se pudieron cargar los datos\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9894b021",
            "metadata": {},
            "source": [
                "## 2. Exploraci√≥n Inicial de Datos\n",
                "\n",
                "### 2.1 Descripci√≥n General"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f454e277",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"INFORMACI√ìN GENERAL DEL DATASET\")\n",
                "print(\"=\"*80)\n",
                "print(f\"\\nDimensiones: {df.shape[0]:,} registros x {df.shape[1]} variables\")\n",
                "print(f\"Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
                "print(\"\\n\" + \"=\"*80)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "de70e657",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vista previa de los datos\n",
                "print(\"Primeras 10 filas del dataset:\")\n",
                "df.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "89c67b36",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Informaci√≥n detallada de columnas\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2438624b",
            "metadata": {},
            "source": [
                "### 2.2 Caracterizaci√≥n de Variables\n",
                "\n",
                "Clasificaremos las variables seg√∫n su tipo y naturaleza para un an√°lisis m√°s estructurado."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "168cb8b1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identificar tipos de variables\n",
                "columnas_numericas = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
                "columnas_categoricas = df.select_dtypes(include=['object']).columns.tolist()\n",
                "columnas_fecha = [col for col in df.columns if 'fecha' in col.lower()]\n",
                "\n",
                "# Variable objetivo\n",
                "variable_objetivo = 'Pago_atiempo'\n",
                "\n",
                "# Eliminar variable objetivo y fechas de las listas si est√°n presentes\n",
                "if variable_objetivo in columnas_numericas:\n",
                "    columnas_numericas.remove(variable_objetivo)\n",
                "for fecha in columnas_fecha:\n",
                "    if fecha in columnas_numericas:\n",
                "        columnas_numericas.remove(fecha)\n",
                "    if fecha in columnas_categoricas:\n",
                "        columnas_categoricas.remove(fecha)\n",
                "\n",
                "print(\"=\"*80)\n",
                "print(\"CARACTERIZACI√ìN DE VARIABLES\")\n",
                "print(\"=\"*80)\n",
                "print(f\"\\nüìä VARIABLE OBJETIVO:\")\n",
                "print(f\"   {variable_objetivo}\")\n",
                "print(f\"\\nüî¢ VARIABLES NUM√âRICAS ({len(columnas_numericas)}):\")\n",
                "for i, col in enumerate(columnas_numericas, 1):\n",
                "    print(f\"   {i:2d}. {col}\")\n",
                "print(f\"\\nüìù VARIABLES CATEG√ìRICAS ({len(columnas_categoricas)}):\")\n",
                "for i, col in enumerate(columnas_categoricas, 1):\n",
                "    print(f\"   {i:2d}. {col}\")\n",
                "print(f\"\\nüìÖ VARIABLES DE FECHA ({len(columnas_fecha)}):\")\n",
                "for i, col in enumerate(columnas_fecha, 1):\n",
                "    print(f\"   {i:2d}. {col}\")\n",
                "print(\"\\n\" + \"=\"*80)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7038e815",
            "metadata": {},
            "source": [
                "### 2.3 An√°lisis de Valores Nulos\n",
                "\n",
                "Identificaremos y cuantificaremos los valores nulos en cada columna."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e425b6c6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# An√°lisis detallado de valores nulos\n",
                "def analizar_nulos(dataframe):\n",
                "    \"\"\"\n",
                "    Analiza valores nulos en el dataframe\n",
                "    \"\"\"\n",
                "    nulos_count = dataframe.isnull().sum()\n",
                "    nulos_pct = (nulos_count / len(dataframe)) * 100\n",
                "    \n",
                "    resumen = pd.DataFrame({\n",
                "        'Columna': dataframe.columns,\n",
                "        'Tipo_Dato': dataframe.dtypes,\n",
                "        'Valores_Nulos': nulos_count.values,\n",
                "        'Porcentaje_Nulos': nulos_pct.values,\n",
                "        'Valores_Unicos': [dataframe[col].nunique() for col in dataframe.columns]\n",
                "    })\n",
                "    \n",
                "    resumen = resumen.sort_values('Valores_Nulos', ascending=False)\n",
                "    return resumen\n",
                "\n",
                "resumen_nulos = analizar_nulos(df)\n",
                "\n",
                "print(\"=\"*80)\n",
                "print(\"AN√ÅLISIS DE VALORES NULOS\")\n",
                "print(\"=\"*80)\n",
                "print(f\"\\nTotal de valores nulos en el dataset: {df.isnull().sum().sum():,}\")\n",
                "print(f\"Porcentaje total de nulos: {(df.isnull().sum().sum() / df.size * 100):.2f}%\\n\")\n",
                "\n",
                "# Mostrar solo columnas con nulos\n",
                "resumen_con_nulos = resumen_nulos[resumen_nulos['Valores_Nulos'] > 0]\n",
                "\n",
                "if len(resumen_con_nulos) > 0:\n",
                "    print(f\"\\nColumnas con valores nulos: {len(resumen_con_nulos)}\\n\")\n",
                "    print(resumen_con_nulos.to_string(index=False))\n",
                "    \n",
                "    # Visualizaci√≥n\n",
                "    if len(resumen_con_nulos) > 0:\n",
                "        plt.figure(figsize=(12, 6))\n",
                "        plt.barh(resumen_con_nulos['Columna'], resumen_con_nulos['Porcentaje_Nulos'], \n",
                "                color='coral', edgecolor='black')\n",
                "        plt.xlabel('Porcentaje de Valores Nulos (%)', fontsize=11)\n",
                "        plt.title('Distribuci√≥n de Valores Nulos por Columna', fontsize=13, fontweight='bold')\n",
                "        plt.grid(axis='x', alpha=0.3)\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "else:\n",
                "    print(\"\\n‚úì No se encontraron valores nulos en ninguna columna\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9b7c116f",
            "metadata": {},
            "source": [
                "### 2.4 Unificar Representaci√≥n de Valores Nulos\n",
                "\n",
                "Convertiremos diferentes representaciones de nulos a un formato est√°ndar."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d1084245",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Valores que deben considerarse como nulos\n",
                "valores_nulos = ['', ' ', 'NA', 'N/A', 'na', 'n/a', 'NULL', 'null', 'None', 'none', '-', '--', '?']\n",
                "\n",
                "print(\"Unificando representaciones de valores nulos...\")\n",
                "print(f\"\\nValores tratados como nulos: {valores_nulos}\")\n",
                "\n",
                "# Reemplazar valores nulos en columnas categ√≥ricas\n",
                "for col in columnas_categoricas:\n",
                "    df[col] = df[col].replace(valores_nulos, np.nan)\n",
                "\n",
                "# Verificar cambios\n",
                "nulos_despues = df.isnull().sum().sum()\n",
                "print(f\"\\nTotal de nulos despu√©s de unificar: {nulos_despues:,}\")\n",
                "print(\"‚úì Valores nulos unificados\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4301a8a9",
            "metadata": {},
            "source": [
                "### 2.5 Conversi√≥n de Tipos de Datos\n",
                "\n",
                "Aseguraremos que cada columna tenga el tipo de dato correcto."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0b89e223",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"CONVERSI√ìN DE TIPOS DE DATOS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Convertir columnas de fecha\n",
                "for col in columnas_fecha:\n",
                "    if col in df.columns:\n",
                "        try:\n",
                "            df[col] = pd.to_datetime(df[col])\n",
                "            print(f\"‚úì {col} convertida a datetime\")\n",
                "        except Exception as e:\n",
                "            print(f\"‚ùå Error al convertir {col}: {str(e)}\")\n",
                "\n",
                "# Verificar y convertir variable objetivo a entero\n",
                "if variable_objetivo in df.columns:\n",
                "    try:\n",
                "        df[variable_objetivo] = df[variable_objetivo].astype(int)\n",
                "        print(f\"‚úì {variable_objetivo} confirmada como int\")\n",
                "    except ValueError:\n",
                "        print(f\"‚ö†Ô∏è No se pudo convertir {variable_objetivo} a int directamente (posibles nulos o valores no num√©ricos)\")\n",
                "\n",
                "print(\"\\nTipos de datos actualizados:\")\n",
                "print(df.dtypes)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bfeb6a93",
            "metadata": {},
            "source": [
                "### 2.6 Identificaci√≥n de Variables Irrelevantes\n",
                "\n",
                "Analizaremos si existen variables que no aportan informaci√≥n al modelo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "386c375c",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"AN√ÅLISIS DE VARIABLES IRRELEVANTES\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "variables_baja_varianza = []\n",
                "variables_muchos_nulos = []\n",
                "variables_constantes = []\n",
                "\n",
                "for col in df.columns:\n",
                "    # Variables con un solo valor √∫nico (constantes)\n",
                "    if df[col].nunique() == 1:\n",
                "        variables_constantes.append(col)\n",
                "    \n",
                "    # Variables con m√°s del 90% de nulos\n",
                "    pct_nulos = (df[col].isnull().sum() / len(df)) * 100\n",
                "    if pct_nulos > 90:\n",
                "        variables_muchos_nulos.append(col)\n",
                "    \n",
                "    # Variables con muy baja varianza (>95% mismo valor para categ√≥ricas)\n",
                "    if col in columnas_categoricas:\n",
                "        if df[col].value_counts(normalize=True).iloc[0] > 0.95:\n",
                "            variables_baja_varianza.append(col)\n",
                "\n",
                "print(f\"\\nVariables constantes (1 valor √∫nico): {len(variables_constantes)}\")\n",
                "if variables_constantes:\n",
                "    print(f\"   {variables_constantes}\")\n",
                "\n",
                "print(f\"\\nVariables con >90% nulos: {len(variables_muchos_nulos)}\")\n",
                "if variables_muchos_nulos:\n",
                "    print(f\"   {variables_muchos_nulos}\")\n",
                "\n",
                "print(f\"\\nVariables con baja varianza (>95% mismo valor): {len(variables_baja_varianza)}\")\n",
                "if variables_baja_varianza:\n",
                "    for var in variables_baja_varianza:\n",
                "        print(f\"   - {var}: {df[var].value_counts(normalize=True).iloc[0]*100:.1f}% es '{df[var].value_counts().index[0]}'\")\n",
                "\n",
                "variables_a_eliminar = list(set(variables_constantes + variables_muchos_nulos))\n",
                "\n",
                "if len(variables_a_eliminar) > 0:\n",
                "    print(f\"\\n‚ö†Ô∏è  Se recomienda eliminar {len(variables_a_eliminar)} variables\")\n",
                "    print(f\"    Variables: {variables_a_eliminar}\")\n",
                "else:\n",
                "    print(\"\\n‚úì No se identificaron variables claramente irrelevantes\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a9fef1c7",
            "metadata": {},
            "source": [
                "## 3. An√°lisis Univariable\n",
                "\n",
                "### 3.1 Variables Num√©ricas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "802a1fc8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Estad√≠sticas descriptivas completas para variables num√©ricas\n",
                "print(\"=\"*80)\n",
                "print(\"ESTAD√çSTICAS DESCRIPTIVAS - VARIABLES NUM√âRICAS\")\n",
                "print(\"=\"*80)\n",
                "df[columnas_numericas].describe().T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "de8d4c61",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Estad√≠sticas adicionales: skewness, kurtosis\n",
                "print(\"=\"*80)\n",
                "print(\"MEDIDAS DE FORMA DE DISTRIBUCI√ìN\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "estadisticas_forma = pd.DataFrame({\n",
                "    'Variable': columnas_numericas,\n",
                "    'Skewness': [df[col].skew() for col in columnas_numericas],\n",
                "    'Kurtosis': [df[col].kurtosis() for col in columnas_numericas]\n",
                "})\n",
                "\n",
                "# Interpretaci√≥n de skewness\n",
                "estadisticas_forma['Interpretacion_Skewness'] = estadisticas_forma['Skewness'].apply(\n",
                "    lambda x: 'Sim√©trica' if abs(x) < 0.5 else ('Asim√©trica derecha' if x > 0 else 'Asim√©trica izquierda')\n",
                ")\n",
                "\n",
                "print(estadisticas_forma.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "acd3e0d5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizaci√≥n: Histogramas y boxplots para variables num√©ricas\n",
                "def plot_distribucion_numerica(df, columnas, filas=4, columnas_grafico=3):\n",
                "    \"\"\"\n",
                "    Crea histogramas y boxplots para variables num√©ricas\n",
                "    \"\"\"\n",
                "    n_cols = len(columnas)\n",
                "    n_filas = (n_cols // columnas_grafico) + (1 if n_cols % columnas_grafico > 0 else 0)\n",
                "    \n",
                "    fig, axes = plt.subplots(n_filas, columnas_grafico, figsize=(18, n_filas * 4))\n",
                "    axes = axes.flatten() if n_cols > 1 else [axes]\n",
                "    \n",
                "    for idx, col in enumerate(columnas):\n",
                "        # Histograma con KDE\n",
                "        axes[idx].hist(df[col].dropna(), bins=50, edgecolor='black', alpha=0.7, density=True)\n",
                "        df[col].dropna().plot(kind='kde', ax=axes[idx], color='red', linewidth=2)\n",
                "        axes[idx].set_title(f'Distribuci√≥n: {col}', fontweight='bold')\n",
                "        axes[idx].set_xlabel('')\n",
                "        axes[idx].grid(alpha=0.3)\n",
                "    \n",
                "    # Ocultar ejes vac√≠os\n",
                "    for idx in range(n_cols, len(axes)):\n",
                "        axes[idx].axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "if len(columnas_numericas) > 0:\n",
                "    print(\"Distribuciones de Variables Num√©ricas:\")\n",
                "    plot_distribucion_numerica(df, columnas_numericas[:9])  # Primeras 9 variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1122d9c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Continuar con m√°s variables si hay m√°s de 9\n",
                "if len(columnas_numericas) > 9:\n",
                "    plot_distribucion_numerica(df, columnas_numericas[9:])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2bac43b2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Boxplots para detectar outliers\n",
                "def plot_boxplots(df, columnas, filas=4, columnas_grafico=3):\n",
                "    \"\"\"\n",
                "    Crea boxplots para variables num√©ricas\n",
                "    \"\"\"\n",
                "    n_cols = len(columnas)\n",
                "    n_filas = (n_cols // columnas_grafico) + (1 if n_cols % columnas_grafico > 0 else 0)\n",
                "    \n",
                "    fig, axes = plt.subplots(n_filas, columnas_grafico, figsize=(18, n_filas * 3))\n",
                "    axes = axes.flatten() if n_cols > 1 else [axes]\n",
                "    \n",
                "    for idx, col in enumerate(columnas):\n",
                "        axes[idx].boxplot(df[col].dropna(), vert=True)\n",
                "        axes[idx].set_title(f'Boxplot: {col}', fontweight='bold')\n",
                "        axes[idx].set_ylabel(col)\n",
                "        axes[idx].grid(alpha=0.3)\n",
                "    \n",
                "    # Ocultar ejes vac√≠os\n",
                "    for idx in range(n_cols, len(axes)):\n",
                "        axes[idx].axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "if len(columnas_numericas) > 0:\n",
                "    print(\"\\nBoxplots para Detecci√≥n de Outliers:\")\n",
                "    plot_boxplots(df, columnas_numericas[:9])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "941bb1b3",
            "metadata": {},
            "outputs": [],
            "source": [
                "if len(columnas_numericas) > 9:\n",
                "    plot_boxplots(df, columnas_numericas[9:])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "196454a7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# An√°lisis de outliers usando IQR\n",
                "def analizar_outliers(df, columnas):\n",
                "    \"\"\"\n",
                "    Detecta outliers usando el m√©todo IQR\n",
                "    \"\"\"\n",
                "    resultados = []\n",
                "    \n",
                "    for col in columnas:\n",
                "        Q1 = df[col].quantile(0.25)\n",
                "        Q3 = df[col].quantile(0.75)\n",
                "        IQR = Q3 - Q1\n",
                "        \n",
                "        limite_inferior = Q1 - 1.5 * IQR\n",
                "        limite_superior = Q3 + 1.5 * IQR\n",
                "        \n",
                "        outliers = df[(df[col] < limite_inferior) | (df[col] > limite_superior)][col]\n",
                "        \n",
                "        resultados.append({\n",
                "            'Variable': col,\n",
                "            'Q1': Q1,\n",
                "            'Q3': Q3,\n",
                "            'IQR': IQR,\n",
                "            'Limite_Inferior': limite_inferior,\n",
                "            'Limite_Superior': limite_superior,\n",
                "            'N_Outliers': len(outliers),\n",
                "            'Porcentaje_Outliers': (len(outliers) / len(df)) * 100\n",
                "        })\n",
                "    \n",
                "    return pd.DataFrame(resultados)\n",
                "\n",
                "print(\"=\"*80)\n",
                "print(\"AN√ÅLISIS DE OUTLIERS (M√âTODO IQR)\")\n",
                "print(\"=\"*80)\n",
                "if len(columnas_numericas) > 0:\n",
                "    outliers_df = analizar_outliers(df, columnas_numericas)\n",
                "    print(outliers_df.to_string(index=False))\n",
                "else:\n",
                "    print(\"No hay variables num√©ricas para analizar outliers\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "52ebdfc8",
            "metadata": {},
            "source": [
                "### 3.2 Variables Categ√≥ricas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "89356ab1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Estad√≠sticas descriptivas para variables categ√≥ricas\n",
                "print(\"=\"*80)\n",
                "print(\"ESTAD√çSTICAS DESCRIPTIVAS - VARIABLES CATEG√ìRICAS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "for col in columnas_categoricas:\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Variable: {col}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    print(f\"Valores √∫nicos: {df[col].nunique()}\")\n",
                "    print(f\"Valor m√°s frecuente: {df[col].mode()[0] if len(df[col].mode()) > 0 else 'N/A'}\")\n",
                "    print(f\"\\nDistribuci√≥n de frecuencias:\")\n",
                "    \n",
                "    frecuencias = df[col].value_counts()\n",
                "    frecuencias_pct = df[col].value_counts(normalize=True) * 100\n",
                "    \n",
                "    resumen = pd.DataFrame({\n",
                "        'Frecuencia': frecuencias,\n",
                "        'Porcentaje': frecuencias_pct\n",
                "    })\n",
                "    \n",
                "    print(resumen.head(10))  # Mostrar top 10 categor√≠as"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b554e9da",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizaci√≥n de variables categ√≥ricas\n",
                "def plot_categoricas(df, columnas):\n",
                "    \"\"\"\n",
                "    Crea gr√°ficos de barras para variables categ√≥ricas\n",
                "    \"\"\"\n",
                "    for col in columnas:\n",
                "        # Verificar si la columna tiene demasiadas categor√≠as\n",
                "        if df[col].nunique() > 50:\n",
                "            print(f\"\\n‚ö†Ô∏è La variable {col} tiene demasiadas categor√≠as ({df[col].nunique()}) para graficar.\")\n",
                "            continue\n",
                "            \n",
                "        plt.figure(figsize=(12, 5))\n",
                "        \n",
                "        # Countplot\n",
                "        value_counts = df[col].value_counts()\n",
                "        plt.subplot(1, 2, 1)\n",
                "        value_counts.head(20).plot(kind='bar', edgecolor='black', alpha=0.7)\n",
                "        plt.title(f'Distribuci√≥n: {col}', fontweight='bold', fontsize=12)\n",
                "        plt.xlabel(col)\n",
                "        plt.ylabel('Frecuencia')\n",
                "        plt.xticks(rotation=45, ha='right')\n",
                "        plt.grid(axis='y', alpha=0.3)\n",
                "        \n",
                "        # Pie chart\n",
                "        plt.subplot(1, 2, 2)\n",
                "        if len(value_counts) <= 10:  # Solo si hay pocas categor√≠as\n",
                "            plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=90)\n",
                "            plt.title(f'Proporci√≥n: {col}', fontweight='bold', fontsize=12)\n",
                "        else:\n",
                "            top10 = value_counts.head(10)\n",
                "            plt.pie(top10, labels=top10.index, autopct='%1.1f%%', startangle=90)\n",
                "            plt.title(f'Proporci√≥n (Top 10): {col}', fontweight='bold', fontsize=12)\n",
                "        \n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "\n",
                "print(\"Distribuciones de Variables Categ√≥ricas:\")\n",
                "plot_categoricas(df, columnas_categoricas)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1dfac403",
            "metadata": {},
            "source": [
                "## 4. An√°lisis Bivariable\n",
                "\n",
                "### 4.1 Relaci√≥n con la Variable Objetivo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5c141c15",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribuci√≥n de la variable objetivo\n",
                "print(\"=\"*80)\n",
                "print(f\"AN√ÅLISIS DE LA VARIABLE OBJETIVO: {variable_objetivo}\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "distribucion_objetivo = df[variable_objetivo].value_counts().sort_index()\n",
                "distribucion_pct = df[variable_objetivo].value_counts(normalize=True).sort_index() * 100\n",
                "\n",
                "print(f\"\\nDistribuci√≥n:\")\n",
                "for clase, count in distribucion_objetivo.items():\n",
                "    print(f\"  Clase {clase}: {count:,} ({distribucion_pct[clase]:.2f}%)\")\n",
                "\n",
                "if len(distribucion_objetivo) > 1:\n",
                "    ratio = min(distribucion_objetivo) / max(distribucion_objetivo)\n",
                "    print(f\"\\nRatio de balance: {ratio:.3f}\")\n",
                "\n",
                "    if ratio < 0.5:\n",
                "        print(\"‚ö†Ô∏è  Dataset desbalanceado - Considerar t√©cnicas de balanceo\")\n",
                "    else:\n",
                "        print(\"‚úì Dataset razonablemente balanceado\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è  La variable objetivo solo tiene una clase!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "73de295b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Variables num√©ricas vs Variable objetivo\n",
                "def analizar_numerica_vs_objetivo(df, columnas_num, var_objetivo):\n",
                "    \"\"\"\n",
                "    Analiza la relaci√≥n entre variables num√©ricas y la variable objetivo\n",
                "    \"\"\"\n",
                "    resultados = []\n",
                "    \n",
                "    for col in columnas_num:\n",
                "        # Estad√≠sticas por clase\n",
                "        try:\n",
                "            clase_0 = df[df[var_objetivo] == 0][col]\n",
                "            clase_1 = df[df[var_objetivo] == 1][col]\n",
                "            \n",
                "            # Test estad√≠stico (t-test)\n",
                "            t_stat, p_value = stats.ttest_ind(clase_0.dropna(), clase_1.dropna())\n",
                "            \n",
                "            resultados.append({\n",
                "                'Variable': col,\n",
                "                'Media_Clase_0': clase_0.mean(),\n",
                "                'Media_Clase_1': clase_1.mean(),\n",
                "                'Diferencia_Medias': abs(clase_0.mean() - clase_1.mean()),\n",
                "                'p_value': p_value,\n",
                "                'Significativa': 'S√≠' if p_value < 0.05 else 'No'\n",
                "            })\n",
                "        except Exception as e:\n",
                "            continue\n",
                "    \n",
                "    if not resultados:\n",
                "        return pd.DataFrame(columns=['Variable', 'Media_Clase_0', 'Media_Clase_1', \n",
                "                                   'Diferencia_Medias', 'p_value', 'Significativa'])\n",
                "\n",
                "    return pd.DataFrame(resultados).sort_values('p_value')\n",
                "\n",
                "print(\"=\"*80)\n",
                "print(\"AN√ÅLISIS BIVARIABLE: VARIABLES NUM√âRICAS VS OBJETIVO\")\n",
                "print(\"=\"*80)\n",
                "analisis_num_objetivo = analizar_numerica_vs_objetivo(df, columnas_numericas, variable_objetivo)\n",
                "print(analisis_num_objetivo.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6c5f7528",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizaci√≥n: Boxplots por clase objetivo\n",
                "def plot_boxplots_por_clase(df, columnas_num, var_objetivo, n_vars=6):\n",
                "    \"\"\"\n",
                "    Crea boxplots comparando distribuciones por clase objetivo\n",
                "    \"\"\"\n",
                "    if len(analisis_num_objetivo) == 0:\n",
                "        return\n",
                "\n",
                "    # Seleccionar variables m√°s significativas\n",
                "    vars_significativas = analisis_num_objetivo.head(n_vars)['Variable'].tolist()\n",
                "    \n",
                "    n_filas = (len(vars_significativas) // 3) + (1 if len(vars_significativas) % 3 > 0 else 0)\n",
                "    fig, axes = plt.subplots(n_filas, 3, figsize=(18, n_filas*5))\n",
                "    axes = axes.flatten() if len(vars_significativas) > 1 else [axes]\n",
                "    \n",
                "    for idx, col in enumerate(vars_significativas):\n",
                "        df.boxplot(column=col, by=var_objetivo, ax=axes[idx])\n",
                "        axes[idx].set_title(f'{col}', fontweight='bold')\n",
                "        axes[idx].set_xlabel(var_objetivo)\n",
                "        axes[idx].set_ylabel(col)\n",
                "    \n",
                "    # Ocultar ejes vac√≠os\n",
                "    for idx in range(len(vars_significativas), len(axes)):\n",
                "        axes[idx].axis('off')\n",
                "\n",
                "    plt.suptitle('Distribuci√≥n de Variables por Clase Objetivo', y=1.02)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "print(\"\\nBoxplots de Variables M√°s Significativas por Clase:\")\n",
                "plot_boxplots_por_clase(df, columnas_numericas, variable_objetivo)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "22ec9c9a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Variables categ√≥ricas vs Variable objetivo\n",
                "def analizar_categorica_vs_objetivo(df, columnas_cat, var_objetivo):\n",
                "    \"\"\"\n",
                "    Analiza la relaci√≥n entre variables categ√≥ricas y la variable objetivo\n",
                "    \"\"\"\n",
                "    resultados = []\n",
                "    \n",
                "    for col in columnas_cat:\n",
                "        if df[col].nunique() > 50: # Saltar variables con demasiadas categor√≠as\n",
                "            continue\n",
                "            \n",
                "        # Tabla de contingencia\n",
                "        tabla_contingencia = pd.crosstab(df[col], df[var_objetivo])\n",
                "        \n",
                "        # Test Chi-cuadrado\n",
                "        try:\n",
                "            chi2, p_value, dof, expected = chi2_contingency(tabla_contingencia)\n",
                "        except:\n",
                "            chi2, p_value = np.nan, np.nan\n",
                "        \n",
                "        # Cram√©r's V (medida de asociaci√≥n)\n",
                "        n = tabla_contingencia.sum().sum()\n",
                "        cramers_v = np.sqrt(chi2 / (n * (min(tabla_contingencia.shape) - 1))) if not np.isnan(chi2) else np.nan\n",
                "        \n",
                "        resultados.append({\n",
                "            'Variable': col,\n",
                "            'Categorias_Unicas': df[col].nunique(),\n",
                "            'Chi2': chi2,\n",
                "            'p_value': p_value,\n",
                "            'Cramers_V': cramers_v,\n",
                "            'Significativa': 'S√≠' if p_value < 0.05 else 'No'\n",
                "        })\n",
                "    \n",
                "    return pd.DataFrame(resultados).sort_values('p_value')\n",
                "\n",
                "if len(columnas_categoricas) > 0:\n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    print(\"AN√ÅLISIS BIVARIABLE: VARIABLES CATEG√ìRICAS VS OBJETIVO\")\n",
                "    print(\"=\"*80)\n",
                "    analisis_cat_objetivo = analizar_categorica_vs_objetivo(df, columnas_categoricas, variable_objetivo)\n",
                "    print(analisis_cat_objetivo.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c019078b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizaci√≥n: Gr√°ficos de barras agrupadas\n",
                "if len(columnas_categoricas) > 0:\n",
                "    for col in columnas_categoricas:\n",
                "        if df[col].nunique() > 20: continue\n",
                "        \n",
                "        plt.figure(figsize=(12, 5))\n",
                "        \n",
                "        # Tabla de contingencia normalizada\n",
                "        tabla = pd.crosstab(df[col], df[variable_objetivo], normalize='index') * 100\n",
                "        \n",
                "        tabla.plot(kind='bar', stacked=False, edgecolor='black', alpha=0.7)\n",
                "        plt.title(f'{col} vs {variable_objetivo}', fontweight='bold', fontsize=13)\n",
                "        plt.xlabel(col)\n",
                "        plt.ylabel('Porcentaje (%)')\n",
                "        plt.xticks(rotation=45, ha='right')\n",
                "        plt.grid(axis='y', alpha=0.3)\n",
                "        plt.tight_layout()\n",
                "        plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "25ddfadd",
            "metadata": {},
            "source": [
                "## 5. An√°lisis Multivariable\n",
                "\n",
                "### 5.1 Matriz de Correlaci√≥n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d3d220f6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calcular matriz de correlaci√≥n\n",
                "print(\"=\"*80)\n",
                "print(\"MATRIZ DE CORRELACI√ìN - VARIABLES NUM√âRICAS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Incluir variable objetivo en la correlaci√≥n\n",
                "cols_para_corr = columnas_numericas + [variable_objetivo]\n",
                "if len(cols_para_corr) > 1:\n",
                "    correlacion = df[cols_para_corr].corr()\n",
                "\n",
                "    # Visualizaci√≥n de la matriz de correlaci√≥n\n",
                "    plt.figure(figsize=(16, 14))\n",
                "    mask = np.triu(np.ones_like(correlacion, dtype=bool))  # M√°scara para tri√°ngulo superior\n",
                "    sns.heatmap(correlacion, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
                "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
                "    plt.title('Matriz de Correlaci√≥n de Variables Num√©ricas', fontsize=14, fontweight='bold', pad=20)\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "104a56d4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identificar correlaciones fuertes\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"CORRELACIONES FUERTES (|r| > 0.7)\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Obtener correlaciones significativas (excluyendo diagonal)\n",
                "correlaciones_fuertes = []\n",
                "if 'correlacion' in locals():\n",
                "    for i in range(len(correlacion.columns)):\n",
                "        for j in range(i+1, len(correlacion.columns)):\n",
                "            if abs(correlacion.iloc[i, j]) > 0.7:\n",
                "                correlaciones_fuertes.append({\n",
                "                    'Variable_1': correlacion.columns[i],\n",
                "                    'Variable_2': correlacion.columns[j],\n",
                "                    'Correlacion': correlacion.iloc[i, j]\n",
                "                })\n",
                "\n",
                "if correlaciones_fuertes:\n",
                "    df_corr_fuertes = pd.DataFrame(correlaciones_fuertes).sort_values('Correlacion', \n",
                "                                                                        key=abs, ascending=False)\n",
                "    print(df_corr_fuertes.to_string(index=False))\n",
                "    print(\"\\n‚ö†Ô∏è  Advertencia: Variables con correlaci√≥n muy alta pueden causar multicolinealidad\")\n",
                "else:\n",
                "    print(\"No se encontraron correlaciones fuertes (|r| > 0.7)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "07bbc6c1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlaci√≥n con la variable objetivo\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"CORRELACI√ìN CON LA VARIABLE OBJETIVO\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "if 'correlacion' in locals() and variable_objetivo in correlacion.columns:\n",
                "    correlacion_objetivo = correlacion[variable_objetivo].drop(variable_objetivo).sort_values(\n",
                "        key=abs, ascending=False\n",
                "    )\n",
                "\n",
                "    print(correlacion_objetivo)\n",
                "\n",
                "    # Visualizaci√≥n\n",
                "    plt.figure(figsize=(10, 8))\n",
                "    correlacion_objetivo.plot(kind='barh', color=['green' if x > 0 else 'red' for x in correlacion_objetivo],\n",
                "                              edgecolor='black', alpha=0.7)\n",
                "    plt.title(f'Correlaci√≥n de Variables con {variable_objetivo}', fontsize=13, fontweight='bold')\n",
                "    plt.xlabel('Coeficiente de Correlaci√≥n')\n",
                "    plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
                "    plt.grid(axis='x', alpha=0.3)\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d9a6318e",
            "metadata": {},
            "source": [
                "### 5.2 Pairplot de Variables Clave"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ece458c9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Seleccionar las 5 variables m√°s correlacionadas con el objetivo\n",
                "if 'correlacion_objetivo' in locals() and not correlacion_objetivo.empty:\n",
                "    top_vars = correlacion_objetivo.head(5).index.tolist()\n",
                "    cols_pairplot = top_vars + [variable_objetivo]\n",
                "\n",
                "    print(f\"Creando pairplot con las variables m√°s relevantes: {top_vars}\")\n",
                "    print(\"Esto puede tomar unos momentos...\")\n",
                "\n",
                "    # Crear pairplot\n",
                "    sns.pairplot(df[cols_pairplot], hue=variable_objetivo, diag_kind='kde', \n",
                "                 plot_kws={'alpha': 0.6}, height=2.5)\n",
                "    plt.suptitle(f'Pairplot de Variables M√°s Correlacionadas con {variable_objetivo}', \n",
                "                 y=1.02, fontsize=14, fontweight='bold')\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "63702e01",
            "metadata": {},
            "source": [
                "## 6. Reglas de Validaci√≥n de Datos\n",
                "\n",
                "Bas√°ndonos en el EDA, establecemos reglas de validaci√≥n para el pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8baee541",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"REGLAS DE VALIDACI√ìN DE DATOS SUGERIDAS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "reglas_validacion = {}\n",
                "\n",
                "for col in df.columns:\n",
                "    regla = {'tipo': str(df[col].dtype)}\n",
                "    if pd.api.types.is_numeric_dtype(df[col]):\n",
                "        regla['min'] = df[col].min()\n",
                "        regla['max'] = df[col].max()\n",
                "    elif pd.api.types.is_datetime64_any_dtype(df[col]):\n",
                "        regla['min'] = df[col].min()\n",
                "        regla['max'] = df[col].max()\n",
                "    elif df[col].nunique() < 20:\n",
                "        regla['valores_validos'] = df[col].dropna().unique().tolist()\n",
                "    \n",
                "    if df[col].isnull().sum() == 0:\n",
                "        regla['permite_nulos'] = False\n",
                "    else:\n",
                "        regla['permite_nulos'] = True\n",
                "        \n",
                "    reglas_validacion[col] = regla\n",
                "\n",
                "print(\"\\nReglas de validaci√≥n inferidas:\")\n",
                "for variable, reglas in list(reglas_validacion.items())[:10]: # Mostrar primeros 10\n",
                "    print(f\"\\n{variable}:\")\n",
                "    for regla, valor in reglas.items():\n",
                "        print(f\"  - {regla}: {valor}\")\n",
                "\n",
                "print(\"\\n... (se muestran solo las primeras 10 variables)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d4a1e527",
            "metadata": {},
            "source": [
                "## 7. Transformaciones Identificadas\n",
                "\n",
                "Documentamos las transformaciones necesarias para la fase de Feature Engineering."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eeab4d8d",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"TRANSFORMACIONES IDENTIFICADAS PARA FEATURE ENGINEERING\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "transformaciones = {\n",
                "    '1. Tratamiento de Nulos': [\n",
                "        f\"- Columnas con nulos: {', '.join(resumen_con_nulos['Columna'].tolist())}\"\n",
                "    ],\n",
                "    '2. Encoding de Variables Categ√≥ricas': [\n",
                "        f\"- Variables a codificar: {', '.join(columnas_categoricas)}\"\n",
                "    ],\n",
                "    '3. Escalado de Variables Num√©ricas': [\n",
                "        \"- Aplicar StandardScaler o MinMaxScaler a todas las variables num√©ricas\"\n",
                "    ]\n",
                "}\n",
                "\n",
                "for categoria, items in transformaciones.items():\n",
                "    print(f\"\\n{categoria}\")\n",
                "    for item in items:\n",
                "        print(f\"  {item}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1ff64dd3",
            "metadata": {},
            "source": [
                "## 8. Conclusiones y Recomendaciones\n",
                "\n",
                "### 8.1 Resumen de Hallazgos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d655cbb2",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"CONCLUSIONES DEL AN√ÅLISIS EXPLORATORIO\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "print(f\"An√°lisis completado para {df.shape[0]} registros.\")\n",
                "print(f\"Se han identificado {len(resumen_con_nulos)} columnas con valores nulos que requieren imputaci√≥n.\")\n",
                "if 'outliers_df' in locals():\n",
                "    print(f\"Se detectaron outliers en {len(outliers_df[outliers_df['N_Outliers'] > 0])} variables num√©ricas.\")\n",
                "\n",
                "print(\"\\nRecomendamos proceder a la fase de limpieza y feature engineering tomando en cuenta las reglas y transformaciones identificadas.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bafc519a",
            "metadata": {},
            "source": [
                "### 8.2 Exportar Resumen del EDA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7b59caad",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Guardar resumen del EDA en archivo de texto\n",
                "ruta_resumen = Path('eda_resumen.txt')\n",
                "\n",
                "with open(ruta_resumen, 'w', encoding='utf-8') as f:\n",
                "    f.write(\"RESUMEN DEL AN√ÅLISIS EXPLORATORIO DE DATOS\\n\")\n",
                "    f.write(\"=\"*80 + \"\\n\\n\")\n",
                "    f.write(f\"Dimensiones: {df.shape}\\n\")\n",
                "\n",
                "print(f\"‚úì Resumen del EDA guardado en: {ruta_resumen.absolute()}\")\n",
                "print(\"\\n‚úì An√°lisis Exploratorio completado exitosamente\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}